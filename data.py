# -*- coding: utf-8 -*-
"""Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18qbmow8ULRz6ZdkNl55EUvPGQ_XTUO2A

Connecting Google Clob with Google Drive

Pytorch utils
"""

import gzip
import shutil
import pandas as pd
import h5py
import gc

import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.utils.data import Dataset

class PCamDataset(Dataset):

    def __init__(self, file_address, part, transform=None, download=False, train=True, chunksize=25000):

        self.transform = transform
        base_address = file_address
        x = []
        y = []

        if train == True:
            with h5py.File(base_address+"train_x.h5", 'r') as db:

                if part == 10:
                    data = db['x'][chunksize*part:]
                else:
                    data = db['x'][chunksize*part:chunksize*(part+1)]

                x = np.array(data.copy(), dtype=np.float32) / 255.0

            with h5py.File(base_address+"train_y.h5", 'r') as db:

                if part == 10:
                    data = db['y'][chunksize*part:]
                else:
                    data = db['y'][chunksize*part:chunksize*(part+1)]

                y = np.array(data.copy(), dtype=np.float32)

        else:
            hf_x = h5py.File(base_address+'valid_x.h5', 'r')
            x = np.array(hf_x.get('x'), dtype=np.float32) / 255.0

            hf_y = h5py.File(base_address+'valid_y.h5', 'r')
            y = np.array(hf_y.get('y'), dtype=np.float32)

        self.x = torch.from_numpy(x.copy()).permute(0, 3, 2, 1)
        self.y = torch.flatten(torch.from_numpy(np.array(y.copy())))

        del x
        del y

        gc.collect()

    def __len__(self):
        return self.x.shape[0]

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


class PCamDataset_NOPART(Dataset):

    def __init__(self, x_file_address, y_file_address, transform=None, download=False, train=True):

        self.transform = transform
        x = []
        y = []

        if train == True:
            with h5py.File(x_file_address, 'r') as db:

                data = db['x']
                x = np.array(data.copy(), dtype=np.float32) / 255.0

            with h5py.File(y_file_address, 'r') as db:

                data = db['y']
                y = np.array(data.copy(), dtype=np.float32)

        else:
            hf_x = h5py.File(base_address+'valid_x.h5', 'r')
            x = np.array(hf_x.get('x'), dtype=np.float32) / 255.0

            hf_y = h5py.File(base_address+'valid_y.h5', 'r')
            y = np.array(hf_y.get('y'), dtype=np.float32)

        self.x = torch.from_numpy(x.copy()).permute(0, 3, 2, 1)
        self.y = torch.flatten(torch.from_numpy(np.array(y.copy())))

        del x
        del y

        gc.collect()

    def __len__(self):
        return self.x.shape[0]

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


class PCam_NoLabel(Dataset):

    def __init__(self, file_name='camelyonpatch_level_2_split_valid_x.h5.gz', part=0, transform=None, download=False, train=True, chunksize=25000):

        self.transform = transform
        base_address = '/content/gdrive/My Drive/Project/'
        x_train = []

        if download == True:

            x_file_name = file_name

            if train == True:
                with gzip.open(base_address + x_file_name, 'rb') as f_in:
                    with open(base_address+"train_x.h5", 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)

            else:
                with gzip.open(base_address + x_file_name, 'rb') as f_in:
                    with open(base_address+"valid_x.h5", 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)

        if train == True:
            with h5py.File(base_address+"train_x.h5", 'r') as db:

                if part == 10:
                    data = db['x'][chunksize*part:]
                else:
                    data = db['x'][chunksize*part:chunksize*(part+1)]

            x_train = np.array(data.copy(), dtype=np.float32) / 255.0

        else:
            hf = h5py.File(base_address+'valid_x.h5', 'r')
            x_train = np.array(hf.get('x'), dtype=np.float32) / 255.0

        psd_lbl = []

        for idx in range(len(x_train)):

            psd_lbl.append(x_train[idx][24:72, 24:72].copy())
            x_train[idx][24:72, 24:72] = np.ones((48, 48, 3)) * 0.5

        self.x_train = torch.from_numpy(x_train.copy()).permute(0, 3, 2, 1)
        self.psd_lbl = torch.from_numpy(np.array(psd_lbl.copy())).permute(0, 3, 2, 1)

        del x_train
        del psd_lbl
        del data

        gc.collect()

    def __len__(self):
        return self.x_train.shape[0]

    def __getitem__(self, idx):
        return self.x_train[idx], self.psd_lbl[idx]

class PCam_Dataset_local(Dataset):

    def __init__(self, file_name='data.h5', part=0, transform=None, train=True, chunksize=25000):

        self.transform = transform
        x_train = []
        psd_lbl = []

        if part == -1:
            if train == True:
                with h5py.File(file_name, 'r') as db:
                    data = db['x']
                    x_train = np.array(data, dtype=np.float32).copy() / 255.0
            else:
                hf = h5py.File(file_name, 'r')
                x_train = np.array(hf.get('x'), dtype=np.float32) / 255.0

        else:
            if train == True:
                with h5py.File(file_name, 'r') as db:
                    if part == 10:
                        data = db['x'][chunksize*part:]
                    else:
                        data = db['x'][chunksize*part:chunksize*(part+1)]

                x_train = np.array(data.copy(), dtype=np.float32) / 255.0

        for idx in range(len(x_train)):

            psd_lbl.append(x_train[idx][24:72, 24:72].copy())
            x_train[idx][24:72, 24:72] = np.ones((48, 48, 3)) * 0.5

        self.x_train = torch.from_numpy(x_train.copy()).permute(0, 3, 2, 1)
        self.psd_lbl = torch.from_numpy(np.array(psd_lbl.copy())).permute(0, 3, 2, 1)

        del x_train
        del psd_lbl
        del data

        gc.collect()

    def __len__(self):
        return self.x_train.shape[0]

    def __getitem__(self, idx):
        return self.x_train[idx], self.psd_lbl[idx]

def prepare_dataset(file_address, name):

    with gzip.open(file_address, 'rb') as f_in:
        with open(name, 'wb') as f_out:
            shutil.copyfileobj(f_in, f_out)

    f_in.close()
    f_out.close()

    return

def merge(file_addr1, file_name1,  file_addr2, file_name2):

    prepare_dataset(file_addr1, file_name1)
    prepare_dataset(file_addr2, file_name2)

    hf1 = h5py.File('Data.h5', 'w')

    with h5py.File(file_name1, 'r') as db1:
        with h5py.File(file_name2, 'r') as db2:
            data = np.append(db1['x'], db2['x'], axis=0)
            hf1.create_dataset('x', data=data)

    hf1.close()
    return

